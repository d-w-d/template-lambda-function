#!/bin/bash
set -e

# Note: This script does NOT use OpenTofu state information to delete resources.
# Instead, it uses only AWS CLI commands and information from your .env file

# Load environment variables
source .env

# Set AWS credentials explicitly with correct case
export AWS_ACCESS_KEY_ID=${aws_access_key_id}
export AWS_SECRET_ACCESS_KEY=${aws_secret_access_key}
export AWS_DEFAULT_REGION=${aws_region}

# Print warning and confirmation
echo "WARNING: This will destroy all AWS infrastructure created by this project."
echo "Resources that will be destroyed:"
echo "- Lambda function: ${LAMBDA_FUNCTION_NAME}"
echo "- S3 bucket: ${S3_BUCKET_NAME} (will be emptied first)"
echo "- API Gateway"
echo "- CloudFront distribution"
echo "- IAM roles and policies"
echo ""
echo "This action cannot be undone."
echo ""
read -p "Are you sure you want to proceed? (y/N) " -n 1 -r
echo ""

if [[ ! $REPLY =~ ^[Yy]$ ]]; then
  echo "Destruction cancelled."
  exit 1
fi

echo "Starting cleanup using AWS CLI only..."

# Delete Lambda function
echo "Deleting Lambda function: ${LAMBDA_FUNCTION_NAME}"
aws lambda delete-function --function-name "${LAMBDA_FUNCTION_NAME}" 2>/dev/null || echo "Lambda function deletion failed or does not exist"

# Find and delete IAM policies related to the lambda
echo "Finding and deleting IAM policies..."
POLICY_ARN=$(aws iam list-policies --scope Local --query "Policies[?PolicyName=='lambda-s3-policy'].Arn" --output text)
if [ ! -z "$POLICY_ARN" ]; then
  # First detach the policy from the role
  echo "Detaching policy ${POLICY_ARN} from role ${LAMBDA_FUNCTION_NAME}-role"
  aws iam detach-role-policy --role-name "${LAMBDA_FUNCTION_NAME}-role" --policy-arn "${POLICY_ARN}" 2>/dev/null || echo "Policy detachment failed"
  
  # Delete the policy
  echo "Deleting policy ${POLICY_ARN}"
  aws iam delete-policy --policy-arn "${POLICY_ARN}" 2>/dev/null || echo "Policy deletion failed"
fi

# Delete IAM role
echo "Deleting IAM role: ${LAMBDA_FUNCTION_NAME}-role"
aws iam delete-role --role-name "${LAMBDA_FUNCTION_NAME}-role" 2>/dev/null || echo "IAM role deletion failed or does not exist"

# Empty and delete S3 bucket
echo "Emptying S3 bucket: ${S3_BUCKET_NAME}"
aws s3 rm "s3://${S3_BUCKET_NAME}" --recursive 2>/dev/null || echo "Failed to empty bucket or bucket does not exist"
echo "Deleting S3 bucket: ${S3_BUCKET_NAME}"
aws s3api delete-bucket --bucket "${S3_BUCKET_NAME}" 2>/dev/null || echo "Bucket deletion failed or bucket does not exist"

# Find and delete API Gateway
echo "Finding API Gateway..."
API_ID=$(aws apigateway get-rest-apis --query "items[?name=='s3-writer-api'].id" --output text)
if [ ! -z "$API_ID" ]; then
  echo "Found API Gateway: $API_ID"
  
  # Delete all API deployments
  echo "Deleting API Gateway deployments..."
  aws apigateway get-deployments --rest-api-id "$API_ID" --query "items[].id" --output text | tr '\t' '\n' | while read -r DEPLOYMENT_ID; do
    aws apigateway delete-deployment --rest-api-id "$API_ID" --deployment-id "$DEPLOYMENT_ID" 2>/dev/null || echo "Deployment deletion failed"
  done
  
  # Delete all API Gateway stages
  echo "Deleting API Gateway stages..."
  aws apigateway get-stages --rest-api-id "$API_ID" --query "item[].stageName" --output text | tr '\t' '\n' | while read -r STAGE_NAME; do
    aws apigateway delete-stage --rest-api-id "$API_ID" --stage-name "$STAGE_NAME" 2>/dev/null || echo "Stage deletion failed"
  done
  
  # Delete resources
  echo "Deleting API Gateway resources..."
  RESOURCES=$(aws apigateway get-resources --rest-api-id "$API_ID" --query "items[?id!='`aws apigateway get-resources --rest-api-id $API_ID --query items[0].id --output text`'].id" --output text)
  for RESOURCE_ID in $RESOURCES; do
    aws apigateway delete-resource --rest-api-id "$API_ID" --resource-id "$RESOURCE_ID" 2>/dev/null || echo "Resource deletion failed"
  done
  
  # Finally delete the API Gateway itself
  echo "Deleting API Gateway: $API_ID"
  aws apigateway delete-rest-api --rest-api-id "$API_ID" 2>/dev/null || echo "API Gateway deletion failed"
else
  echo "No API Gateway found with name 's3-writer-api'"
fi

# Find and delete CloudFront distributions linked to the S3 bucket
echo "Finding CloudFront distributions for bucket ${S3_BUCKET_NAME}..."
DIST_IDS=$(aws cloudfront list-distributions --query "DistributionList.Items[?contains(Origins.Items[0].DomainName, '${S3_BUCKET_NAME}')].Id" --output text)
if [ ! -z "$DIST_IDS" ]; then
  for DIST_ID in $DIST_IDS; do
    echo "Found CloudFront distribution: $DIST_ID"
    
    # Check if distribution is already disabled
    IS_ENABLED=$(aws cloudfront get-distribution --id "$DIST_ID" --query "Distribution.DistributionConfig.Enabled" --output text)
    if [ "$IS_ENABLED" = "true" ]; then
      # First, disable the distribution (required before deletion)
      echo "Disabling CloudFront distribution..."
      ETAG=$(aws cloudfront get-distribution-config --id "$DIST_ID" --query "ETag" --output text)
      aws cloudfront update-distribution --id "$DIST_ID" --if-match "$ETAG" --distribution-config "$(aws cloudfront get-distribution-config --id "$DIST_ID" --query "DistributionConfig" | sed 's/"Enabled": true/"Enabled": false/')" 2>/dev/null || echo "Failed to disable distribution"
      
      echo "CloudFront distribution is being disabled."
      echo "IMPORTANT: Disabling CloudFront distributions can take 15-30 minutes to complete."
      echo "Once disabled, run this command to delete it:"
      echo "aws cloudfront delete-distribution --id $DIST_ID --if-match \$(aws cloudfront get-distribution-config --id $DIST_ID --query \"ETag\" --output text)"
    else
      # Distribution is already disabled, delete it
      echo "Deleting CloudFront distribution..."
      ETAG=$(aws cloudfront get-distribution-config --id "$DIST_ID" --query "ETag" --output text)
      aws cloudfront delete-distribution --id "$DIST_ID" --if-match "$ETAG" 2>/dev/null || echo "CloudFront deletion failed"
    fi
  done
else
  echo "No CloudFront distributions found with the specified S3 bucket origin."
fi

# Clean up CloudWatch log groups
echo "Cleaning up CloudWatch log groups..."
aws logs delete-log-group --log-group-name "/aws/lambda/${LAMBDA_FUNCTION_NAME}" 2>/dev/null || echo "CloudWatch log group deletion failed or does not exist"

echo "Cleanup completed."
echo "Note: Some resources like CloudFront distributions may still be in the process of deletion."
echo "CloudFront distributions can take 15-30 minutes to fully delete after being disabled."
